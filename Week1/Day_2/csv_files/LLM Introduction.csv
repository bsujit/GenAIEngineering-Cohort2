filename,page_number,chunk_number,chunk
LLM Introduction.pdf,1,1,Introduction to large langu
LLM Introduction.pdf,1,2,age models (LLMs) INTRODUCT
LLM Introduction.pdf,1,3,ION TO LLMS IN PYTHON Jasmi
LLM Introduction.pdf,1,4,n Ludolf Senior Data Scienc
LLM Introduction.pdf,1,5,"e Content Developer, DataCamp"
LLM Introduction.pdf,2,1,INTRODUCTION TO LLMS
LLM Introduction.pdf,2,2, IN PYTHON Previous 
LLM Introduction.pdf,2,3,knowledge Navigating
LLM Introduction.pdf,2,4, the Hugging Face Hu
LLM Introduction.pdf,2,5,b Deep learning models
LLM Introduction.pdf,3,1,INTRODUCTI
LLM Introduction.pdf,3,2,ON TO LLMS
LLM Introduction.pdf,3,3, IN PYTHON
LLM Introduction.pdf,3,4, Introduct
LLM Introduction.pdf,3,5,ion to LLMs
LLM Introduction.pdf,4,1,INTRODUCTI
LLM Introduction.pdf,4,2,ON TO LLMS
LLM Introduction.pdf,4,3, IN PYTHON
LLM Introduction.pdf,4,4,Introducti
LLM Introduction.pdf,4,5,on to LLMs
LLM Introduction.pdf,5,1,INTROD
LLM Introduction.pdf,5,2,UCTION
LLM Introduction.pdf,5,3, TO LL
LLM Introduction.pdf,5,4,MS IN 
LLM Introduction.pdf,5,5,PYTHON
LLM Introduction.pdf,6,1,INTROD
LLM Introduction.pdf,6,2,UCTION
LLM Introduction.pdf,6,3, TO LL
LLM Introduction.pdf,6,4,MS IN 
LLM Introduction.pdf,6,5,PYTHON
LLM Introduction.pdf,7,1,INTROD
LLM Introduction.pdf,7,2,UCTION
LLM Introduction.pdf,7,3, TO LL
LLM Introduction.pdf,7,4,MS IN 
LLM Introduction.pdf,7,5,PYTHON
LLM Introduction.pdf,8,1,INTROD
LLM Introduction.pdf,8,2,UCTION
LLM Introduction.pdf,8,3, TO LL
LLM Introduction.pdf,8,4,MS IN 
LLM Introduction.pdf,8,5,PYTHON
LLM Introduction.pdf,9,1,INTROD
LLM Introduction.pdf,9,2,UCTION
LLM Introduction.pdf,9,3, TO LL
LLM Introduction.pdf,9,4,MS IN 
LLM Introduction.pdf,9,5,PYTHON
LLM Introduction.pdf,10,1,INTRODUCTION TO LLMS IN PYTHON 
LLM Introduction.pdf,10,2,LLMs Based on deep learning arc
LLM Introduction.pdf,10,3,hitectures Most commonly transf
LLM Introduction.pdf,10,4,ormers Huge neural networks wit
LLM Introduction.pdf,10,5,h lots of parameters and text data
LLM Introduction.pdf,11,1,"INTRODUCTION TO LLMS IN PYTHON Using Hugging Face models from transformers import pipeline summarizer = pipeline(task=""summarization"", "
LLM Introduction.pdf,11,2,"model=""facebook/bart-large-cnn"") text = ""Walking amid Gion's Machiya wooden houses is a mesmerizing experience. The beautifully preserv"
LLM Introduction.pdf,11,3,"ed structures exuded an old-world charm that transports visitors back in time, making them feel like they had stepped into a living mus"
LLM Introduction.pdf,11,4,"eum. The glow of lanterns lining the narrow streets add to the enchanting ambiance, making each stroll a memorable journey through Japa"
LLM Introduction.pdf,11,5,"n's rich cultural history."" summary = summarizer(text, max_length=50) clean_up_tokenization_spaces=True: remove unnecessary white space"
LLM Introduction.pdf,12,1,"INTRODUCTION TO LLMS IN PYTHON Model outputs print(summary) [{'summary_text': ""Gion's Machiya wooden houses exuded"
LLM Introduction.pdf,12,2, an old-world charm that transports visitors back in time. The glow of lanterns lining the narrow streets add to t
LLM Introduction.pdf,12,3,"he enchanting ambiance, making each stroll a memorable journey through Japan's""}] print(summary[0][""summary_text""]"
LLM Introduction.pdf,12,4,) Gion's Machiya wooden houses exuded an old-world charm that transports visitors back in time. The glow of lanter
LLM Introduction.pdf,12,5,"ns lining the narrow streets add to the enchanting ambiance, making each stroll a memorable journey through Japan's"
LLM Introduction.pdf,13,1,INTRODUCTION TO LLMS IN PYTHON
LLM Introduction.pdf,13,2, Up next Build on existing LLM
LLM Introduction.pdf,13,3, knowledge Perform new tasks S
LLM Introduction.pdf,13,4,ee how LLMs are built Fine-tun
LLM Introduction.pdf,13,5,e LLMs Evaluate LLM performance
LLM Introduction.pdf,14,1,Let's pra
LLM Introduction.pdf,14,2,ctice! IN
LLM Introduction.pdf,14,3,TRODUCTIO
LLM Introduction.pdf,14,4,N TO LLMS
LLM Introduction.pdf,14,5, IN PYTHON
LLM Introduction.pdf,15,1,Using pre-trained LLMs 
LLM Introduction.pdf,15,2,INTRODUCTION TO LLMS IN
LLM Introduction.pdf,15,3, PYTHON Jasmin Ludolf S
LLM Introduction.pdf,15,4,enior Data Science Cont
LLM Introduction.pdf,15,5,"ent Developer, DataCamp"
LLM Introduction.pdf,16,1,INTRODUCTI
LLM Introduction.pdf,16,2,ON TO LLMS
LLM Introduction.pdf,16,3, IN PYTHON
LLM Introduction.pdf,16,4, Language 
LLM Introduction.pdf,16,5,understanding
LLM Introduction.pdf,17,1,INTRODUCT
LLM Introduction.pdf,17,2,ION TO LL
LLM Introduction.pdf,17,3,MS IN PYT
LLM Introduction.pdf,17,4,HONLangua
LLM Introduction.pdf,17,5,ge generation
LLM Introduction.pdf,18,1,INTRODUCTION TO LLMS IN PYTHON Text generation generator = pipelin
LLM Introduction.pdf,18,2,"e(task=""text-generation"", model=""distilgpt2"") prompt = ""The Gion n"
LLM Introduction.pdf,18,3,"eighborhood in Kyoto is famous for"" output = generator(prompt, max"
LLM Introduction.pdf,18,4,"_length=100, pad_token_id=generator.tokenizer.eos_token_id) Cohere"
LLM Introduction.pdf,18,5,nt Meaningful Human-like text eos_token_id: end-of-sequence token ID
LLM Introduction.pdf,19,1,INTRODUCTION TO LLMS IN PYTHONText generation pad_token_id
LLM Introduction.pdf,19,2,: fills in extra space up to max_length Padding: adding to
LLM Introduction.pdf,19,3,kens Setting to generator.tokenizer.eos_token_id marks the
LLM Introduction.pdf,19,4," end of meaningful text, learned through training Model ge"
LLM Introduction.pdf,19,5,nerates up to max_length or pad_token_id truncation = True
LLM Introduction.pdf,20,1,"INTRODUCTION TO LLMS IN PYTHONText generation generator = pipeline(task=""text-generation"", model=""distilg"
LLM Introduction.pdf,20,2,"pt2"") prompt = ""The Gion neighborhood in Kyoto is famous for"" output = generator(prompt, max_length=100, "
LLM Introduction.pdf,20,3,"pad_token_id=generator.tokenizer.eos_token_id) print(output[0][""generated_text""]) The Gion neighborhood i"
LLM Introduction.pdf,20,4,"n Kyoto is famous for its many colorful green forests, such as the Red Hill, the Red River and the Red Ri"
LLM Introduction.pdf,20,5,ver. The Gion neighborhood is home to the world's tallest trees. Output may be suboptimal if prompt is vague
LLM Introduction.pdf,21,1,"INTRODUCTION TO LLMS IN PYTHON Guiding the output generator = pipeline(task=""text-generation"", model=""dis"
LLM Introduction.pdf,21,2,"tilgpt2"") review = ""This book was great. I enjoyed the plot twist in Chapter 10."" response = ""Dear reader"
LLM Introduction.pdf,21,3,", thank you for your review."" prompt = f""Book review:\n{review}\n\nBook shop response to the review:\n{re"
LLM Introduction.pdf,21,4,"sponse}"" output = generator(prompt, max_length=100, pad_token_id=generator.tokenizer.eos_token_id) print("
LLM Introduction.pdf,21,5,"output[0][""generated_text""]) Dear reader, thank you for your review. We'd like to thank you for your reading!"
LLM Introduction.pdf,22,1,INTRODUCTION TO LLMS IN PYTHON Language translation Hugging Face has a complete list of tran
LLM Introduction.pdf,22,2,"slation tasks and models translator = pipeline(task=""translation_en_to_es"", model=""Helsinki-"
LLM Introduction.pdf,22,3,"NLP/opus-mt-en-es"") text = ""Walking amid Gion's Machiya wooden houses was a mesmerizing expe"
LLM Introduction.pdf,22,4,"rience."" output = translator(text, clean_up_tokenization_spaces=True) print(output[0][""trans"
LLM Introduction.pdf,22,5,"lation_text""]) Caminar entre las casas de madera Machiya de Gion fue una experiencia fascinante."
LLM Introduction.pdf,23,1,Let's pra
LLM Introduction.pdf,23,2,ctice! IN
LLM Introduction.pdf,23,3,TRODUCTIO
LLM Introduction.pdf,23,4,N TO LLMS
LLM Introduction.pdf,23,5, IN PYTHON
LLM Introduction.pdf,24,1,Understanding the transf
LLM Introduction.pdf,24,2,ormer INTRODUCTION TO LL
LLM Introduction.pdf,24,3,MS IN PYTHON Jasmin Ludo
LLM Introduction.pdf,24,4,lf Senior Data Science C
LLM Introduction.pdf,24,5,"ontent Developer, DataCamp"
LLM Introduction.pdf,25,1,INTRODUCTION TO LLMS IN PYTHON What i
LLM Introduction.pdf,25,2,s a transformer? Deep learning archit
LLM Introduction.pdf,25,3,"ectures Processing, understanding, an"
LLM Introduction.pdf,25,4,d generating text Used in most LLMs H
LLM Introduction.pdf,25,5,andle long text sequences in parallel
LLM Introduction.pdf,26,1,INTRODUCTION TO LLMS IN
LLM Introduction.pdf,26,2, PYTHON Transformer arc
LLM Introduction.pdf,26,3,hitectures Find the arc
LLM Introduction.pdf,26,4,hitecture details in th
LLM Introduction.pdf,26,5,e Hugging Face model card
LLM Introduction.pdf,27,1,INTRODUCTION TO LLMS IN PYTHON Encoder-only Underst
LLM Introduction.pdf,27,2,anding the input text No sequential output Common t
LLM Introduction.pdf,27,3,asks: Text classification Sentiment analysis Extrac
LLM Introduction.pdf,27,4,tive question-answering (extract or label) BERT mod
LLM Introduction.pdf,27,5,"els Example: ""distilbert-base-uncased-distilled- squad"""
LLM Introduction.pdf,28,1,INTRODUCTION TO LLMS IN PYTHONEncoder-only llm =
LLM Introduction.pdf,28,2," pipeline(model=""bert-base-uncased"") print(llm.m"
LLM Introduction.pdf,28,3,odel) BertForMaskedLM( (bert): ... ) (encoder): 
LLM Introduction.pdf,28,4,BertEncoder( ... print(llm.model.config) BertCon
LLM Introduction.pdf,28,5,"fig { ... ""architectures"": [ ""BertForMaskedLM"" ..."
LLM Introduction.pdf,29,1,INTRODUCTION TO LLMS IN PY
LLM Introduction.pdf,29,2,THONEncoder-only print(llm
LLM Introduction.pdf,29,3,.model.config.is_decoder) 
LLM Introduction.pdf,29,4,False Alternatively: llm.m
LLM Introduction.pdf,29,5,odel.config.is_encoder_decoder
LLM Introduction.pdf,30,1,INTRODUCTION TO LLMS IN PYTHON Decoder
LLM Introduction.pdf,30,2,-only Focus shifts to output Common ta
LLM Introduction.pdf,30,3,sks: Text generation Generative questi
LLM Introduction.pdf,30,4,on-answering (sentence(s) or paragraph
LLM Introduction.pdf,30,5,"(s)) GPT models Example: ""gpt-3.5-turbo"""
LLM Introduction.pdf,31,1,INTRODUCTION TO LLMS IN PYTHONDecoder-only llm = 
LLM Introduction.pdf,31,2,"pipeline(model=""gpt2"") print(llm.model.config) GP"
LLM Introduction.pdf,31,3,"T2Config { ... ""architectures"": [ ""GPT2LMHeadMode"
LLM Introduction.pdf,31,4,"l"" ], ... ""task_specific_params"": { ""text-generat"
LLM Introduction.pdf,31,5,"ion"": { ... print(llm.model.config.is_decoder) False"
LLM Introduction.pdf,32,1,INTRODUCTION TO LLMS IN PYTHO
LLM Introduction.pdf,32,2,N Encoder-decoder Understand 
LLM Introduction.pdf,32,3,and process the input and out
LLM Introduction.pdf,32,4,put Common tasks: Translation
LLM Introduction.pdf,32,5," Summarization T5, BART models"
LLM Introduction.pdf,33,1,INTRODUCTION TO LLMS IN PYTHONEncoder-
LLM Introduction.pdf,33,2,"decoder llm = pipeline(model=""Helsinki"
LLM Introduction.pdf,33,3,"-NLP/opus-mt-es-en"") print(llm.model) "
LLM Introduction.pdf,33,4,MarianMTModel( ... (encoder): MarianEn
LLM Introduction.pdf,33,5,coder( ... (decoder): MarianDecoder( ...
LLM Introduction.pdf,34,1,INTRODUCTION TO LLMS IN PYTHONEncoder-decoder p
LLM Introduction.pdf,34,2,"rint(llm.model.config) MarianConfig { ... ""deco"
LLM Introduction.pdf,34,3,"der_attention_heads"": 8, ... ""encoder_attention"
LLM Introduction.pdf,34,4,"_heads"": 8, ... ""is_encoder_decoder"": true, ..."
LLM Introduction.pdf,34,5, print(llm.model.config.is_encoder_decoder) True
LLM Introduction.pdf,35,1,Let's pra
LLM Introduction.pdf,35,2,ctice! IN
LLM Introduction.pdf,35,3,TRODUCTIO
LLM Introduction.pdf,35,4,N TO LLMS
LLM Introduction.pdf,35,5, IN PYTHON
